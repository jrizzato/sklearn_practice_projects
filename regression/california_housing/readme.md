# California Housing Dataset - Regresi贸n Lineal

## Descripci贸n del Dataset

El dataset California Housing contiene informaci贸n sobre viviendas en California basada en el censo de 1990. Se utiliza para predecir el **precio medio de las casas** en diferentes bloques geogr谩ficos.

---

## Caracter铆sticas del Dataset

### **Tipo de Problema**
- **Regresi贸n** (predicci贸n de valores continuos)
- Variable objetivo: Precio de viviendas

### **Dimensiones**
- **20,640 muestras** (observaciones)
- **8 caracter铆sticas** (features)
- **1 variable objetivo** (target)

---

## Variable Objetivo (Target)

- **PRECIO**: Precio medio de las casas (en $100,000s)
- **Rango t铆pico**: 0.15 a 5.0 (aproximadamente $15,000 a $500,000)

---

## Correlaciones Importantes

| Caracter铆stica | Correlaci贸n con Precio | Descripci贸n |
|----------------|------------------------|-------------|
| **MedInc** | Alta positiva (~0.68) | El ingreso es el mejor predictor del precio |
| **Latitude** | Media | Ubicaci贸n norte-sur afecta el precio |
| **Longitude** | Media | Ubicaci贸n este-oeste afecta el precio |
| **HouseAge** | Baja | Edad de la casa tiene efecto limitado |
| **AveOccup** | Muy baja | Ocupaci贸n promedio poco correlacionada |

---

## Caracter铆sticas Relevantes para Modelado

### Consideraciones
- **Contiene outliers** (especialmente en AveRooms, AveBedrms)
- **Relaciones no perfectamente lineales**
- **Datos hist贸ricos** (1990) - pueden no reflejar precios actuales
- **Datos agregados** - no son viviendas individuales

---

## T茅cnicas de Machine Learning Aplicables

### Implementadas en este proyecto
- **Regresi贸n Lineal** - Baseline simple y efectivo

### T茅cnicas Recomendadas

#### Modelos Lineales
- **Ridge Regression** - Regularizaci贸n L2 para reducir overfitting
- **Lasso Regression** - Regularizaci贸n L1 y selecci贸n de features
- **ElasticNet** - Combinaci贸n de Ridge y Lasso

#### Modelos Basados en rboles
- **Decision Tree Regressor** - Captura relaciones no lineales
- **Random Forest** - Ensemble de 谩rboles, robusto a outliers
- **Gradient Boosting** - Alta precisi贸n (XGBoost, LightGBM, CatBoost)

#### Otros Modelos
- **Support Vector Regression (SVR)** - Efectivo en espacios de alta dimensi贸n
- **K-Nearest Neighbors (KNN)** - Basado en similitud geogr谩fica
- **Neural Networks** - Para relaciones complejas

---

## Cu谩ndo Usar Estas T茅cnicas

Aplica t茅cnicas similares cuando encuentres datasets con:

-  **Problema de regresi贸n** (predicci贸n de valores continuos)
-  **Features num茅ricas** en diferentes escalas
-  **Miles de observaciones** (dataset mediano a grande)
-  **Relaciones no perfectamente lineales**
-  **Datos geogr谩ficos** (coordenadas lat/lon)
-  **Datos agregados** por grupos, bloques o regiones
-  **Presencia de outliers** que deben manejarse

---

## M茅tricas de Evaluaci贸n

Para este problema de regresi贸n, las m茅tricas relevantes son:

| M茅trica | Descripci贸n | Interpretaci贸n |
|---------|-------------|----------------|
| **R虏 Score** | Proporci贸n de varianza explicada | 0-1, mayor es mejor |
| **MSE** | Error cuadr谩tico medio | Menor es mejor |
| **RMSE** | Ra铆z del MSE (mismas unidades) | Menor es mejor |
| **MAE** | Error absoluto medio | Menor es mejor, robusto a outliers |

---

## Resultados del Modelo

### Regresi贸n Lineal
- **R虏 Score**: ~0.60 (explica 60% de la varianza)
- **MSE**: ~0.52
- **RMSE**: ~0.72 ($72,000 de error promedio)

---

## Mejoras Potenciales

1. **Ingenier铆a de Features**
   - Crear interacciones (ej: MedInc  Latitude)
   - Features polin贸micas
   - Transformaciones logar铆tmicas

2. **Preprocesamiento**
   - Normalizaci贸n/Estandarizaci贸n de features
   - Manejo de outliers
   - Feature selection

3. **Modelos Avanzados**
   - Probar Random Forest o Gradient Boosting
   - Hyperparameter tuning con GridSearchCV
   - Ensemble methods

4. **Validaci贸n**
   - Cross-validation
   - Validaci贸n en datos de diferentes a帽os

---

##  Informaci贸n del Proyecto

- **Fecha de creaci贸n**: 13 de diciembre de 2025
- **Lenguaje**: Python
- **Librer铆as**: scikit-learn, pandas, numpy, matplotlib, seaborn
- **Modelo**: Regresi贸n Lineal
